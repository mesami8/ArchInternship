# ArchInternship
This repository is for my internship tasks which are given in monthly bases 
 #taskNo2
Medical Finetuning With Qlora Using Unsloth In Colab
Implement a QLoRA-based fine-tuning workflow for a medical language model
using Unsloth’s prebuilt notebooks in Google Colab. Load a domain-specific medical
dataset (e.g., clinical Q&A pairs), configure Unsloth to run 4-bit quantized low-rank
adaptation on a base model like Llama 3 or DeepSeek-R1, and execute the training
workflow including tokenization, adapter setup, and epoch-based training. Monitor
memory use and performance via Colab, save your fine-tuned adapter, and test the
model’s responses on new medical queries. This project helps you learn efficient
PEFT workflows, memory-saving techniques, and how to adapt models to
specialized medical domains
